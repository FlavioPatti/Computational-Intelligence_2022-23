{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from collections import namedtuple\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from itertools import accumulate\n",
    "from operator import xor\n",
    "\n",
    "\n",
    "Nimply = namedtuple(\"Nimply\", \"row, num_objects\")\n",
    "\n",
    "class Nim:\n",
    "    def __init__(self, num_rows: int, k: int = None):\n",
    "        self._rows = [i * 2 + 1 for i in range(num_rows)]\n",
    "        #self._rows = [0,1,3]\n",
    "        self._k = k\n",
    "\n",
    "    def __bool__(self):\n",
    "        return sum(self._rows) > 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<\" + \" \".join(str(_) for _ in self._rows) + \">\"\n",
    "\n",
    "    @property\n",
    "    def rows(self) -> tuple:\n",
    "        return tuple(self._rows)\n",
    "\n",
    "    @property\n",
    "    def k(self):\n",
    "        return self._k\n",
    "    \n",
    "    #apply the chosen move by removing num_objects from the row\n",
    "    def nimming(self, ply: Nimply):\n",
    "        row, num_objects = ply\n",
    "        assert self._rows[row] >= num_objects\n",
    "        assert self._k is None or num_objects <= self._k\n",
    "        self._rows[row] -= num_objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dumb_PCI(state: Nim):\n",
    "    \"\"\"Pick always the minimum(maximum) possible number of the lowest row\"\"\"\n",
    "    possible_moves = [(r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1)]\n",
    "    return Nimply(*max(possible_moves, key=lambda m: (-m[0], -m[1])))\n",
    "\n",
    "def pure_random(state: Nim):\n",
    "    row = random.choice([r for r, c in enumerate(state.rows) if c > 0])\n",
    "    num_objects = random.randint(1, state.rows[row])\n",
    "    return Nimply(row, num_objects)\n",
    "\n",
    "\"\"\"optimal strategy\"\"\"\n",
    "def nim_sum(state: Nim):\n",
    "    *_, result = accumulate(state.rows, xor)\n",
    "    return result\n",
    "\n",
    "def cook_status(state: Nim):\n",
    "    cooked = dict()\n",
    "    cooked[\"possible_moves\"] = [\n",
    "        (r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1) if state.k is None or o <= state.k\n",
    "    ]\n",
    "    cooked[\"active_rows_number\"] = sum(o > 0 for o in state.rows)\n",
    "    cooked[\"shortest_row\"] = min((x for x in enumerate(state.rows) if x[1] > 0), key=lambda y: y[1])[0]\n",
    "    cooked[\"longest_row\"] = max((x for x in enumerate(state.rows)), key=lambda y: y[1])[0]\n",
    "    cooked[\"nim_sum\"] = nim_sum(state)\n",
    "\n",
    "    brute_force = list()\n",
    "    for m in cooked[\"possible_moves\"]:\n",
    "        tmp = deepcopy(state)\n",
    "        tmp.nimming(m)\n",
    "        brute_force.append((m, nim_sum(tmp)))\n",
    "    cooked[\"brute_force\"] = brute_force\n",
    "\n",
    "    return cooked\n",
    "\n",
    "def optimal_startegy(state: Nim):\n",
    "    data = cook_status(state)\n",
    "    return next((bf for bf in data[\"brute_force\"] if bf[1] == 0), random.choice(data[\"brute_force\"]))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pesi iniziali = {(1, 3, 5): 0, (0, 3, 5): 0.33703263554681673, (0, 2, 5): 0.9353799619814587, (0, 1, 5): 0.27281310888400523, (0, 0, 5): 0.2601257629364474, (0, 0, 4): 0.3938645121068185, (0, 0, 3): 0.41897722728339903, (0, 0, 2): 0.6247435984311518, (0, 0, 1): 0.4494709384863894, (0, 0, 0): 0.7137336404724113, (0, 1, 4): 0.21346937350604855, (0, 1, 3): 0.7136510849850632, (0, 1, 2): 0.28361033859059315, (0, 1, 1): 0.7489363928040482, (0, 1, 0): 0.8822984102563569, (0, 2, 4): 0.2701992978319818, (0, 2, 3): 0.5571126532732044, (0, 2, 2): 0.1499122889378176, (0, 2, 1): 0.5810823253613915, (0, 2, 0): 0.12052597834433398, (0, 3, 4): 0.3492633602155988, (0, 3, 3): 0.9071771956028485, (0, 3, 2): 0.6573332880748318, (0, 3, 1): 0.9598486257434682, (0, 3, 0): 0.6173936249140268, (1, 2, 5): 0.293754689756908, (1, 1, 5): 0.4133618292940936, (1, 0, 5): 0.6309741224113308, (1, 0, 4): 0.8629218612241196, (1, 0, 3): 0.4381782611137971, (1, 0, 2): 0.41376522243840574, (1, 0, 1): 0.11113365808279296, (1, 0, 0): 0.47378924973548076, (1, 1, 4): 0.8810751700917586, (1, 1, 3): 0.5814776020057282, (1, 1, 2): 0.8858997904137577, (1, 1, 1): 0.7536301642077382, (1, 1, 0): 0.7227948170204874, (1, 2, 4): 0.7683801431832943, (1, 2, 3): 0.1635651342845752, (1, 2, 2): 0.6468959058944351, (1, 2, 1): 0.27350621644603346, (1, 2, 0): 0.3849300192060171, (1, 3, 4): 0.7541588177826019, (1, 3, 3): 0.9525652370139986, (1, 3, 2): 0.353861030204905, (1, 3, 1): 0.8189614267658496, (1, 3, 0): 0.33899442266803026}\n",
      "pesi finali = {(1, 3, 5): 0, (0, 3, 5): -1999.7737127987136, (0, 2, 5): 0.9353799619814587, (0, 1, 5): 0.27281310888400523, (0, 0, 5): 0.2601257629364474, (0, 0, 4): 0.3938645121068185, (0, 0, 3): -1944.9285841668375, (0, 0, 2): -1181.7974307957436, (0, 0, 1): -2366.499887926378, (0, 0, 0): -1555.7134416164106, (0, 1, 4): 0.21346937350604855, (0, 1, 3): -1846.7871670835507, (0, 1, 2): -1277.6401971667135, (0, 1, 1): -1218.747212212693, (0, 1, 0): -2302.49209971489, (0, 2, 4): 0.2701992978319818, (0, 2, 3): -2061.698432958497, (0, 2, 2): -1423.5813460061538, (0, 2, 1): -1654.0519549478306, (0, 2, 0): -2086.093429309215, (0, 3, 4): 0.3492633602155988, (0, 3, 3): 0.9071771956028485, (0, 3, 2): -1870.7827652327587, (0, 3, 1): -1795.9053393540937, (0, 3, 0): -2065.957156809261, (1, 2, 5): -2351.1914508342397, (1, 1, 5): -2051.4054743798533, (1, 0, 5): -1972.1104362787341, (1, 0, 4): 0.8629218612241196, (1, 0, 3): -2367.3989331326443, (1, 0, 2): -1337.826577820267, (1, 0, 1): -1334.9844636308183, (1, 0, 0): -2363.8117621759025, (1, 1, 4): 0.8810751700917586, (1, 1, 3): -1169.4912330631846, (1, 1, 2): -1218.8702135234214, (1, 1, 1): -874.9867893482194, (1, 1, 0): -1452.5215502198248, (1, 2, 4): 0.7683801431832943, (1, 2, 3): 0.1635651342845752, (1, 2, 2): -2372.6166019022335, (1, 2, 1): -2200.24563199821, (1, 2, 0): -1590.8528458075205, (1, 3, 4): -1778.8634999670303, (1, 3, 3): -2138.060436229414, (1, 3, 2): -1773.7118267362596, (1, 3, 1): -2236.704573704827, (1, 3, 0): -2309.3573636202846}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nwon = 0\\nfor i in range(10):\\n    player = 0\\n    while nim:\\n        if player == 0:\\n            ply = test(nim)\\n        else:\\n            ply = optimal_startegy(nim)\\n            nim.nimming(ply)\\n        player = 1 - player\\n        nim = Nim(3)\\n    if player == 1:\\n        won += 1\\n        \\nwin_rate = won / 10\\nprint(win_rate)\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "alpha=0.15\n",
    "random_factor=0.2  # 80% explore, 20% exploit\n",
    "state_history = []\n",
    "rewards = {}\n",
    "NUM_MATCHES = 100\n",
    "\n",
    "def give_rewards(state: Nim):\n",
    "      # if at end give 0 reward\n",
    "      # if not at end give -1 reward\n",
    "    if not state:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def init_reward(nim):  \n",
    "    if not nim:\n",
    "        return\n",
    "    \n",
    "    allowedMoves = allowed_moves(nim)\n",
    "    for move in allowedMoves:\n",
    "        tmp = deepcopy(nim)\n",
    "        tmp.nimming(move)\n",
    "        new_state = tuple(tmp.rows)\n",
    "        rewards[new_state] = np.random.uniform(low=1.0, high=0.1)\n",
    "        init_reward(tmp)\n",
    "    \n",
    "\n",
    "def choose_action(nim, allowedMoves, rewards):\n",
    "        maxG = -10e15\n",
    "        next_move = None\n",
    "        randomN = np.random.random()\n",
    "        if randomN < random_factor:\n",
    "            # if random number below random factor, choose random action\n",
    "            index = np.random.randint(0, len(allowedMoves))\n",
    "            next_move = allowedMoves[index]\n",
    "        else:\n",
    "            # if exploiting, gather all possible actions and choose one with the highest G (reward)\n",
    "            for action in allowedMoves:\n",
    "                tmp = deepcopy(nim)\n",
    "                tmp.nimming(action)\n",
    "                new_state = tmp.rows\n",
    "                if rewards[new_state] >= maxG:\n",
    "                    next_move = action\n",
    "                    maxG = rewards[new_state]\n",
    "            \n",
    "        return next_move\n",
    "    \n",
    "def allowed_moves(nim):\n",
    "    return [\n",
    "        (r, o) for r, c in enumerate(nim.rows) for o in range(1, c + 1)\n",
    "    ]\n",
    "\n",
    "def learn(rewards, state_history, random_factor):\n",
    "        target = 0\n",
    "        for prev, reward in reversed(state_history):\n",
    "            rewards[tuple(prev)] = rewards[tuple(prev)] + alpha * (target - rewards[tuple(prev)])\n",
    "            target += reward\n",
    "\n",
    "        state_history = []\n",
    "        random_factor -= 10e-5  # decrease random factor each episode of play\n",
    "        \n",
    "def reinforcement_learning(nim):\n",
    "    allowedMoves = allowed_moves(nim)\n",
    "    action = choose_action(nim,allowedMoves, rewards)\n",
    "    nim.nimming(action)\n",
    "    rew = give_rewards(nim)\n",
    "    state_history.append((nim.rows, rew))\n",
    "    learn(rewards, state_history, random_factor)\n",
    "    \n",
    "    return action\n",
    "\n",
    "def test(nim):\n",
    "    allowedMoves = allowed_moves(nim)\n",
    "    action = choose_action(nim,allowedMoves, rewards)\n",
    "    nim.nimming(action)\n",
    "    \n",
    "    return action\n",
    "\n",
    "    \n",
    "nim = Nim(3)\n",
    "rewards[nim.rows] =  0\n",
    "init_reward(nim)\n",
    "print(f\"pesi iniziali = {rewards}\")\n",
    "\n",
    "\"\"\"Training\"\"\"\n",
    "for i in range(1000):\n",
    "    player = 0\n",
    "    while nim:\n",
    "        if player == 0:\n",
    "            ply = reinforcement_learning(nim)\n",
    "        else:\n",
    "            ply = optimal_startegy(nim)\n",
    "            nim.nimming(ply)\n",
    "        \n",
    "        player = 1 - player\n",
    "    winner = 1 - player\n",
    "    nim = Nim(3)\n",
    "    \n",
    "print(f\"pesi finali = {rewards}\")\n",
    "\n",
    "\"\"\"Test\"\"\"\n",
    "nim = Nim(3)\n",
    "won = 0\n",
    "\n",
    "for i in range(10):\n",
    "    player = 0\n",
    "    while nim:\n",
    "        if player == 0:\n",
    "            ply = test(nim)\n",
    "        else:\n",
    "            ply = optimal_startegy(nim)\n",
    "            nim.nimming(ply)\n",
    "        player = 1 - player\n",
    "        \n",
    "    if player == 1:\n",
    "        won += 1\n",
    "        \n",
    "    nim = Nim(3)\n",
    "        \n",
    "win_rate = won / 10\n",
    "print(win_rate)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9cff5a362bc38ef45d817ae74b1af54d6a076e3d773891282bce078b815ba34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
